# -*- coding: utf-8 -*-
"""telecom-x.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zhqM92ogKKsQtde89fgYN9jCKQ6D4_Yz
"""

import requests
import pandas as pd

# 1. URL correta (raw do GitHub)
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json"

# 2. Fazer a requisi√ß√£o GET
response = requests.get(url)

# 3. Verificar se a resposta foi bem-sucedida
if response.status_code == 200:
    dados = response.json()  # Converte para dicion√°rio/lista em Python

    # 4. Converter para DataFrame
    df = pd.DataFrame(dados)

    # 5. Exibir os 5 primeiros registros
    print(df.head())
else:
    print(f"Erro ao acessar API: {response.status_code}")

"""1. Explorar as colunas e verificar tipos de dados"""

import requests
import pandas as pd

# URL raw do JSON no GitHub
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json"

# Requisi√ß√£o
response = requests.get(url)
dados = response.json()

# Criar DataFrame
df = pd.DataFrame(dados)

# Ver os tipos de dados de cada coluna
print(df.dtypes)

# Resumo completo (linhas, colunas, tipos, valores nulos)
print(df.info())

"""2. Inspe√ß√£o

"""

import requests
import pandas as pd

# ==========================
# 1. Carregar os dados da API (GitHub raw)
# ==========================
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json"
response = requests.get(url)
dados = response.json()

# Normalizar se houver dicion√°rios aninhados
df = pd.json_normalize(dados)

print("\n‚úÖ Dataset carregado e normalizado com sucesso!")
print("Dimens√£o:", df.shape)

# ==========================
# 2. Informa√ß√µes iniciais
# ==========================
print("\nüìã Informa√ß√µes do DataFrame:")
print(df.info())

print("\nTipos de dados:")
print(df.dtypes)

# ==========================
# 3. Verifica√ß√£o de valores ausentes
# ==========================
print("\nüîé Valores ausentes (contagem):")
print(df.isnull().sum())

print("\n% de valores ausentes por coluna:")
print((df.isnull().mean() * 100).round(2))

# ==========================
# 4. Verifica√ß√£o de duplicados
# ==========================
try:
    duplicados = df.duplicated().sum()
    print(f"\nüìå Registros duplicados encontrados: {duplicados}")
    if duplicados > 0:
        df = df.drop_duplicates()
        print("‚Üí Duplicados removidos.")
except TypeError:
    print("\n‚ö†Ô∏è Algumas colunas t√™m listas/dicion√°rios. Ignorando checagem de duplicados.")

# ==========================
# 5. Convers√£o de colunas num√©ricas
# ==========================
if "TotalCharges" in df.columns:
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
    print(f"\n‚ö†Ô∏è Valores inv√°lidos em 'TotalCharges' ap√≥s convers√£o: {df['TotalCharges'].isnull().sum()}")

# ==========================
# 6. Padroniza√ß√£o de categorias (object)
# ==========================
for col in df.select_dtypes(include="object").columns:
    df[col] = df[col].astype(str).str.strip().str.lower()

print("\nüîë Categorias √∫nicas ap√≥s padroniza√ß√£o:")
for col in df.select_dtypes(include="object").columns[:5]:  # mostra s√≥ 5 primeiras para n√£o poluir
    print(f"\nColuna: {col}")
    print(df[col].value_counts(dropna=False).head(10))

# ==========================
# 7. Resumo final
# ==========================
print("\nüìä Dataset ap√≥s limpeza:")
print(df.info())
print("Dimens√£o final:", df.shape)
print("Colunas:", df.columns.tolist())

"""3. Corre√ß√µes


"""

import requests
import pandas as pd

# ==========================
# 1. Carregar e normalizar os dados
# ==========================
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json"
response = requests.get(url)
dados = response.json()

df = pd.json_normalize(dados)  # normaliza estruturas aninhadas
print("‚úÖ Dados carregados. Dimens√£o inicial:", df.shape)

# ==========================
# 2. Remover duplicados (se poss√≠vel)
# ==========================
try:
    df = df.drop_duplicates()
    print("‚Üí Duplicados removidos.")
except TypeError:
    print("‚ö†Ô∏è Algumas colunas t√™m listas/dicion√°rios. Duplicados ignorados.")

# ==========================
# 3. Ajustar colunas num√©ricas
# ==========================
# Converter TotalCharges para float
if "TotalCharges" in df.columns:
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

# Se houver valores nulos em TotalCharges (clientes rec√©m-entrados), preenche com 0
if "TotalCharges" in df.columns:
    df["TotalCharges"].fillna(0, inplace=True)

# ==========================
# 4. Ajustar colunas categ√≥ricas
# ==========================
for col in df.select_dtypes(include="object").columns:
    df[col] = df[col].astype(str).str.strip().str.lower()

# Padronizar Churn para "yes" / "no"
if "churn" in df.columns:
    df["churn"] = df["churn"].replace({"yes": 1, "no": 0})

# ==========================
# 5. Ajustar colunas inteiras
# ==========================
if "SeniorCitizen" in df.columns:
    df["SeniorCitizen"] = df["SeniorCitizen"].astype(int)

# ==========================
# 6. Tratar valores ausentes
# ==========================
# Excluir colunas com muitos NaN (opcional: threshold 40%)
limite = len(df) * 0.4
df = df.dropna(axis=1, thresh=limite)

# Preencher valores categ√≥ricos ausentes com "unknown"
for col in df.select_dtypes(include="object").columns:
    df[col].fillna("unknown", inplace=True)

# ==========================
# 7. Resumo final
# ==========================
print("\nüìä Dataset pronto para an√°lise!")
print("Dimens√£o final:", df.shape)
print("\nTipos de dados:")
print(df.dtypes)
print("\nValores ausentes restantes:")
print(df.isnull().sum().sum())

"""4. Conta di√°ria

"""

import requests
import pandas as pd

# ==========================
# 1. Carregar e normalizar os dados
# ==========================
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json"
response = requests.get(url)
dados = response.json()

# Normaliza o JSON caso haja colunas aninhadas
df = pd.json_normalize(dados)
print("‚úÖ Dados carregados e normalizados. Dimens√£o inicial:", df.shape)

# ==========================
# 2. Remover duplicados (se poss√≠vel)
# ==========================
try:
    df = df.drop_duplicates()
    print("‚Üí Duplicados removidos.")
except TypeError:
    print("‚ö†Ô∏è Algumas colunas t√™m listas/dicion√°rios. Duplicados ignorados.")

# ==========================
# 3. Ajustar colunas num√©ricas
# ==========================
# Conferir nomes das colunas para encontrar o faturamento mensal
print("\nColunas dispon√≠veis:", df.columns.tolist())

# Supondo que a coluna de faturamento seja 'MonthlyCharges' ou variante
faturamento_col = [col for col in df.columns if "monthly" in col.lower()]
if len(faturamento_col) == 0:
    raise KeyError("N√£o foi poss√≠vel localizar a coluna de faturamento mensal!")
else:
    faturamento_col = faturamento_col[0]
    print(f"\nUsando '{faturamento_col}' como coluna de faturamento mensal.")

# Converter para num√©rico
df[faturamento_col] = pd.to_numeric(df[faturamento_col], errors="coerce")

# Preencher valores ausentes com 0
df[faturamento_col].fillna(0, inplace=True)

# ==========================
# 4. Criar coluna Contas_Diarias
# ==========================
df["Contas_Diarias"] = (df[faturamento_col] / 30).round(2)

# ==========================
# 5. Ajustar colunas categ√≥ricas
# ==========================
for col in df.select_dtypes(include="object").columns:
    df[col] = df[col].astype(str).str.strip().str.lower()

# Converter Churn para bin√°rio se existir
if "churn" in df.columns:
    df["churn"] = df["churn"].replace({"yes": 1, "no": 0})

# ==========================
# 6. Ajustar colunas inteiras
# ==========================
if "SeniorCitizen" in df.columns:
    df["SeniorCitizen"] = pd.to_numeric(df["SeniorCitizen"], errors="coerce").fillna(0).astype(int)

# ==========================
# 7. Tratar valores ausentes restantes
# ==========================
# Excluir colunas com muitos NaN (opcional: threshold 40%)
limite = len(df) * 0.4
df = df.dropna(axis=1, thresh=limite)

# Preencher valores categ√≥ricos ausentes com "unknown"
for col in df.select_dtypes(include="object").columns:
    df[col].fillna("unknown", inplace=True)

# ==========================
# 8. Resumo final
# ==========================
print("\nüìä Dataset pronto para an√°lise!")
print("Dimens√£o final:", df.shape)
print("\nTipos de dados:")
print(df.dtypes)
print("\nValores ausentes restantes:", df.isnull().sum().sum())
print("\nExemplo da nova coluna 'Contas_Diarias':")
print(df[["Contas_Diarias", faturamento_col]].head())



# An√°lise descritiva das colunas num√©ricas
print("\nüìä An√°lise Descritiva das Colunas Num√©ricas:")
display(df.describe())

# An√°lise descritiva das colunas categ√≥ricas
print("\nüìä An√°lise Descritiva das Colunas Categ√≥ricas:")
display(df.select_dtypes(include='object').describe())

# Contagem de valores √∫nicos para algumas colunas categ√≥ricas importantes
print("\nüìä Contagem de Valores √önicos para Colunas Categ√≥ricas:")
for col in ['Churn', 'customer.gender', 'customer.Partner', 'customer.Dependents', 'account.Contract', 'internet.InternetService']:
    if col in df.columns:
        print(f"\n--- {col} ---")
        display(df[col].value_counts())

import matplotlib.pyplot as plt
import seaborn as sns

# Contagem dos valores na coluna 'Churn'
churn_counts = df['Churn'].value_counts()

# Criar o gr√°fico de barras
plt.figure(figsize=(6, 4))
sns.barplot(x=churn_counts.index, y=churn_counts.values)
plt.title('Distribui√ß√£o de Churn')
plt.xlabel('Churn')
plt.ylabel('N√∫mero de Clientes')
plt.show()

# Mostrar a propor√ß√£o em porcentagem
print("\nPropor√ß√£o de Churn:")
print(df['Churn'].value_counts(normalize=True) * 100)

import matplotlib.pyplot as plt
import seaborn as sns

categorical_cols = ['customer.gender', 'customer.Partner', 'customer.Dependents',
                    'phone.PhoneService', 'phone.MultipleLines', 'internet.InternetService',
                    'internet.OnlineSecurity', 'internet.OnlineBackup', 'internet.DeviceProtection',
                    'internet.TechSupport', 'internet.StreamingTV', 'internet.StreamingMovies',
                    'account.Contract', 'account.PaperlessBilling', 'account.PaymentMethod']

for col in categorical_cols:
    if col in df.columns:
        plt.figure(figsize=(8, 5))
        sns.countplot(data=df, x=col, hue='Churn')
        plt.title(f'Distribui√ß√£o de Churn por {col}')
        plt.xlabel(col)
        plt.ylabel('N√∫mero de Clientes')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

numerical_cols = ['customer.tenure', 'account.Charges.Monthly', 'account.Charges.Total']

for col in numerical_cols:
    if col in df.columns:
        plt.figure(figsize=(8, 5))
        sns.boxplot(data=df, x='Churn', y=col)
        plt.title(f'Distribui√ß√£o de {col} por Churn')
        plt.xlabel('Churn')
        plt.ylabel(col)
        plt.show()

        plt.figure(figsize=(8, 5))
        sns.histplot(data=df, x=col, hue='Churn', multiple='stack', kde=True)
        plt.title(f'Histograma de {col} por Churn')
        plt.xlabel(col)
        plt.ylabel('N√∫mero de Clientes')
        plt.show()

"""# Relat√≥rio de An√°lise de Evas√£o de Clientes (Churn)

## Introdu√ß√£o

Este relat√≥rio apresenta uma an√°lise explorat√≥ria do dataset TelecomX_Data, com o objetivo de entender o fen√¥meno da evas√£o de clientes (Churn) em uma empresa de telecomunica√ß√µes. O Churn √© um desafio significativo para empresas de servi√ßos, pois a aquisi√ß√£o de novos clientes geralmente custa mais do que a reten√ß√£o dos clientes existentes. A an√°lise busca identificar padr√µes e fatores que contribuem para a evas√£o, fornecendo insights para estrat√©gias de reten√ß√£o mais eficazes.

## Limpeza e Tratamento de Dados

Os dados foram carregados a partir de um arquivo JSON hospedado no GitHub. Durante a etapa de limpeza e tratamento, foram realizadas as seguintes a√ß√µes:

*   **Carregamento e Normaliza√ß√£o:** Os dados foram importados utilizando a biblioteca `requests` para acessar o arquivo JSON e `pandas` para convert√™-lo em um DataFrame. A fun√ß√£o `pd.json_normalize` foi utilizada para lidar com as estruturas aninhadas no JSON, resultando em colunas flattenadas.
*   **Remo√ß√£o de Duplicados:** Verificou-se e removeu-se registros duplicados no dataset.
*   **Ajuste de Colunas Num√©ricas:** A coluna 'account.Charges.Total' foi convertida para o tipo num√©rico (`float`), tratando poss√≠veis erros de convers√£o com `errors='coerce'` e preenchendo valores ausentes (que podem representar clientes novos sem cobran√ßa total) com 0. A coluna 'account.Charges.Monthly' tamb√©m foi tratada.
*   **Cria√ß√£o da coluna Contas_Diarias**: Foi criada uma nova coluna 'Contas_Diarias' calculando a m√©dia di√°ria do faturamento mensal.
*   **Ajuste de Colunas Categ√≥ricas:** As colunas do tipo 'object' foram padronizadas para letras min√∫sculas e espa√ßos em branco removidos para garantir consist√™ncia nos valores categ√≥ricos.
*   **Tratamento de Valores Ausentes:** Foi realizada uma verifica√ß√£o e tratamento de valores ausentes.

## An√°lise Explorat√≥ria de Dados

A an√°lise explorat√≥ria de dados (AED) foi conduzida para visualizar a distribui√ß√£o das vari√°veis e identificar poss√≠veis rela√ß√µes com o Churn.

### Distribui√ß√£o de Churn

A distribui√ß√£o da vari√°vel Churn (`fd2be5e0`) mostrou a propor√ß√£o de clientes que cancelaram e que n√£o cancelaram o servi√ßo.

<div align="center">
  <img src="https://colab.research.googleusercontent.com/outputframe/asyncthetic_image.png?id=fd2be5e0-1755650753" width="400" height="300">
</div>

### Rela√ß√£o do Churn com Vari√°veis Categ√≥ricas

Foram gerados gr√°ficos de barras (`5f9543e4`) para visualizar a distribui√ß√£o de Churn em rela√ß√£o a diversas vari√°veis categ√≥ricas, como g√™nero, tipo de contrato, servi√ßo de internet, etc. Esses gr√°ficos (`5f9543e4`) revelaram insights sobre quais categorias apresentam maior ou menor taxa de evas√£o.

<div align="center">
  <img src="https://colab.research.googleusercontent.com/outputframe/asyncthetic_image.png?id=5f9543e4-1755650790" width="600" height="400">
</div>

### Rela√ß√£o do Churn com Vari√°veis Num√©ricas

A rela√ß√£o entre o Churn e vari√°veis num√©ricas como tempo de contrato (`customer.tenure`), gastos mensais (`account.Charges.Monthly`) e gastos totais (`account.Charges.Total`) foi explorada atrav√©s de boxplots e histogramas (`113c4f97`). Esses gr√°ficos ajudaram a identificar se valores mais altos ou mais baixos nessas vari√°veis est√£o associados a uma maior probabilidade de Churn.

<div align="center">
  <img src="https://colab.research.googleusercontent.com/outputframe/asyncthetic_image.png?id=113c4f97-1755650820" width="600" height="400">
</div>

## Conclus√µes e Insights

Com base na an√°lise realizada, podemos destacar alguns insights importantes:

*   Clientes com **contratos de m√™s a m√™s** apresentam uma taxa de Churn significativamente maior em compara√ß√£o com clientes com contratos de um ou dois anos.
*   Clientes que utilizam **servi√ßos de internet de Fibra √ìtica** parecem ter uma taxa de Churn maior do que aqueles com DSL ou sem servi√ßo de internet.
*   Clientes com **menor tempo de contrato (tenure)** t√™m maior probabilidade de evadir. A taxa de Churn tende a diminuir √† medida que o tempo de contrato aumenta.
*   N√£o houve diferen√ßa significativa na taxa de Churn entre **g√™neros**.
*   Clientes com **Dependentes** ou **Parceiros** parecem ter menor taxa de Churn.
*   Clientes que utilizam **Pagamento Eletr√¥nico** apresentaram maior taxa de Churn.
*   Clientes com **gastos mensais mais altos** parecem ter maior probabilidade de Churn.

Esses insights sugerem que o tipo de contrato, servi√ßo de internet, tempo de contrato e m√©todo de pagamento s√£o fatores importantes a serem considerados na previs√£o e preven√ß√£o do Churn.

## Recomenda√ß√µes

Com base nas conclus√µes da an√°lise explorat√≥ria, as seguintes recomenda√ß√µes podem ser consideradas para reduzir a evas√£o de clientes:

*   **Programas de Fidelidade para Contratos Longos:** Incentivar clientes com contratos de m√™s a m√™s a migrarem para contratos de maior dura√ß√£o (um ou dois anos) atrav√©s de descontos ou benef√≠cios exclusivos.
*   **Melhoria na Qualidade do Servi√ßo de Fibra √ìtica:** Investigar as raz√µes por tr√°s da maior taxa de Churn entre usu√°rios de fibra √≥tica e implementar melhorias na qualidade do servi√ßo, suporte t√©cnico ou comunica√ß√£o.
*   **Estrat√©gias de Reten√ß√£o para Novos Clientes:** Focar em a√ß√µes de engajamento e suporte nos primeiros meses de contrato para clientes com menor tempo de servi√ßo.
*   **An√°lise Detalhada de M√©todos de Pagamento:** Investigar se h√° problemas espec√≠ficos associados ao m√©todo de pagamento eletr√¥nico que possam estar contribuindo para o Churn.
*   **Ofertas Personalizadas:** Utilizar os insights da an√°lise para criar ofertas personalizadas para clientes com maior risco de Churn, como descontos em servi√ßos adicionais ou um atendimento mais proativo.

Este relat√≥rio fornece uma base s√≥lida para entender o Churn. Para um modelo preditivo mais robusto, as pr√≥ximas etapas envolveriam a prepara√ß√£o dos dados para modelagem, sele√ß√£o e treinamento de modelos de machine learning e avalia√ß√£o do desempenho.
"""